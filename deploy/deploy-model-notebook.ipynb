{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import LocalWebservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inference configuration based on the environment definition and the entry script\n",
    "myenv = Environment.get(ws, \"diabetes-env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ローカル環境で Debug\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=8890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(ws, \"diabetes-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model diabetes-model:2 to /tmp/azureml_8iqfqh_8/diabetes-model/2\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry f79f2067feb24fe5bd660f1f5123e456.azurecr.io\n",
      "Logging into Docker registry f79f2067feb24fe5bd660f1f5123e456.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM f79f2067feb24fe5bd660f1f5123e456.azurecr.io/azureml/azureml_16a60a5e0afc11b3b7176c7e7784bb27\n",
      " ---> 097fa6aa5147\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 1f570cf6fbc7\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjgyYTVkOGQzLTUzMjItNGM0OS1iOWQ2LWRhNmUwMGJlNWQ1NyIsInJlc291cmNlR3JvdXBOYW1lIjoiYXp1cmVtbCIsImFjY291bnROYW1lIjoiYXp1cmVtbCIsIndvcmtzcGFjZUlkIjoiZjc5ZjIwNjctZmViMi00ZmU1LWJkNjYtMGYxZjUxMjNlNDU2In0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in b82097672c05\n",
      " ---> 2817c0be9877\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpkf25vmsl.py' /var/azureml-app/main.py\n",
      " ---> Running in 02d1b2f56e07\n",
      " ---> 49e09ee6dff9\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 280ee4811123\n",
      " ---> 7ab1f9dbebcc\n",
      "Successfully built 7ab1f9dbebcc\n",
      "Successfully tagged dia:latest\n",
      "Container (name:reverent_wescoff, id:23c97f44277e14d0f6f246b0734579dcd5d572d734a01148f203212ef4c30364) cannot be killed.\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:1948a2d763d84b69f0b373d110fd9a8f7878cb809ebb88551b88614c1c30990f successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n"
     ]
    }
   ],
   "source": [
    "local_service = Model.deploy(\n",
    "    ws, \"dia\", [model], inference_config, deployment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-29T13:46:11,694763454+00:00 - iot-server/run \n",
      "2020-12-29T13:46:11,694837155+00:00 - gunicorn/run \n",
      "2020-12-29T13:46:11,694823255+00:00 - rsyslog/run \n",
      "2020-12-29T13:46:11,696614073+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-12-29T13:46:12,023014116+00:00 - iot-server/finish 1 0\n",
      "2020-12-29T13:46:12,024324329+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (10)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2020-12-29 13:46:14,964 | root | INFO | Starting up app insights client\n",
      "Starting up app insights client\n",
      "2020-12-29 13:46:14,965 | root | INFO | Starting up request id generator\n",
      "Starting up request id generator\n",
      "2020-12-29 13:46:14,965 | root | INFO | Starting up app insight hooks\n",
      "Starting up app insight hooks\n",
      "2020-12-29 13:46:14,965 | root | INFO | Invoking user's init function\n",
      "Invoking user's init function\n",
      "2020-12-29 13:46:14,975 | root | INFO | Users's init has completed successfully\n",
      "Users's init has completed successfully\n",
      "2020-12-29 13:46:14,978 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2020-12-29 13:46:14,979 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2020-12-29 13:46:14,979 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(local_service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name=\"test\",\n",
    "                       models=[model],\n",
    "                       inference_config=inference_config,\n",
    "                       deployment_config=aci_config,\n",
    "                       overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running..............................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
